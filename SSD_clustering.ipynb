{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project\n",
        "* **Aim:** To validate the performance of **Single-Shot-Detection** when the data is clustered and each cluster is used to train a separate model. \n",
        "* **Process overview:**\n",
        "    1. Download PascalVOC Dataset of the year 2012(you can download others). \n",
        "    1. Use Pretrained *VGG-16 model* to get the feature vector of images in the data.\n",
        "    2. Cluster the images based on their feature vectors by MiniBatchKMeans(to avoid RAM Crash).\n",
        "    3. Initialize num_clusters no. of SSD models, training each with a different set of data(data from each clusters).\n",
        "    4. Train a SSD model with the whole data.\n",
        "    5. Validate the difference in performance between the two approaches\n"
      ],
      "metadata": {
        "id": "I06doxoCE8wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/harshraj172/SSD_clustering.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plHkdlquSA31",
        "outputId": "4b1e36de-5886-4cc5-d5c6-057733bde84d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SSD_clustering'...\n",
            "remote: Enumerating objects: 179, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 179 (delta 56), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (179/179), 56.50 KiB | 4.35 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GQTx78V4Hk3t"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# For commands\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "os.chdir('/content/')\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For visualization\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import imageio as io\n",
        "from pylab import *\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "#For model performance\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cdist\n",
        "import joblib\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "\n",
        "# For array manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.util.testing as tm\n",
        "import os\n",
        "import random\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from SSD_clustering.data.PascalVOC.Dataset import SSDDataset\n",
        "from SSD_clustering.utils.utils import *\n",
        "from SSD_clustering.utils import AuxiliaryConvolutions, PredictionConvolutions, Loss\n",
        "from SSD_clustering.model import ssd, base_model"
      ],
      "metadata": {
        "id": "c3ns7OR-9Bg-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initSeeds(seed=1):\n",
        "\tprint(f\"initSeeds({seed})\")\n",
        "\trandom.seed(seed)\n",
        "\ttorch.manual_seed(seed) \t#turn on this 2 lines when torch is being used\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\tnp.random.seed(seed)"
      ],
      "metadata": {
        "id": "pi-T0F6No_V4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cuda(cudadevice='cuda:0'):\n",
        "\t\"\"\" return the best Cuda device \"\"\"\n",
        "\tdevid = cudadevice\n",
        "\t#print ('Current cuda device ', devid, torch.cuda.get_device_name(devid))\n",
        "\t#device = 'cuda:0'\t#most of the time torch choose the right CUDA device\n",
        "\treturn torch.device(devid)\t\t#use this device object instead of the device string"
      ],
      "metadata": {
        "id": "ru5nv1LFP5NZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onceInit(kCUDA=False, cudadevice='cuda:0', seed=1):\n",
        "\t#print(f\"onceInit {cudadevice}\")\n",
        "\tif kCUDA and torch.cuda.is_available():\n",
        "\t\tif cudadevice is None:\n",
        "\t\t\tdevice = get_cuda()\n",
        "\t\telse:\n",
        "\t\t\tdevice = torch.device(cudadevice)\n",
        "\t\t\ttorch.cuda.set_device(device)\n",
        "\telse:\n",
        "\t\tdevice = 'cpu'\n",
        "\n",
        "\tprint(f\"torchutils.onceInit device = {device}\")\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\ttorch.backends.cudnn.enabled = kCUDA\n",
        "\n",
        "\tinitSeeds(seed)\n",
        "\n",
        "\treturn device"
      ],
      "metadata": {
        "id": "3ZlVNw7bpiLC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MVEhsvHiHm1-"
      },
      "outputs": [],
      "source": [
        "def downloadVOC(save_path='./data/', year='2012', download=True):\n",
        "  \"\"\"downloads the PascalVOC Dataset\"\"\"\n",
        "  datasets.VOCDetection(root=save_path, year=year, download=download, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ABg_vr-NH1Nt"
      },
      "outputs": [],
      "source": [
        "def transformIMG(imgsize=300, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "  \"\"\"Resize the raw image, Normalize it\"\"\"\n",
        "  tsfm = transforms.Compose([\n",
        "      transforms.Resize([imgsize, imgsize]),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean, std),\n",
        "  ])\n",
        "  return tsfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SampleFromData(img_folder_path, n:int):\n",
        "  \"\"\"Sample img path from the full list of images\"\"\"\n",
        "  imgFile_names = []\n",
        "  for file_ in os.listdir(img_folder_path):\n",
        "    imgFile_names.append(file_)\n",
        "  \n",
        "  # return random.sample(imgFile_names, n)\n",
        "  return imgFile_names[:n]"
      ],
      "metadata": {
        "id": "RcgTsaoWt08y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readURL(url):\n",
        "  resp = requests.get(url)\n",
        "  data = json.loads(resp.text)\n",
        "  return data"
      ],
      "metadata": {
        "id": "sRAKfqdy1mjd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auxiliary Convolutions**\n",
        "\n",
        "It is used as the additional transformation of the feature vector generated through base model which is then used in concatenation with the former."
      ],
      "metadata": {
        "id": "jr-9WTDCc5zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extractFeatures(\n",
        "    img,\n",
        "    model,\n",
        "    model_name='vgg16',\n",
        "    method='m1',\n",
        "    ):\n",
        "    \"\"\"\n",
        "  Different ways for feature extraction to be used in Clustering\n",
        "  Arguments:\n",
        "  img((int, int, int)): batch of images(batch_size, imgsize, imgsize)\n",
        "  model: loaded model for feature extraction\n",
        "  model_name(str, optional): the model to use for feature extraction\n",
        "  method(str, optional): different methods tried for feature extraction\n",
        "                         m1-> the features are extracted in the same way as is done by the base_model in SSD\n",
        "                         m2-> takes the last layer output of the model, does avgPooling and passes through \n",
        "                              the first layer of the classifier architecture\n",
        "  \"\"\"\n",
        "\n",
        "    if model_name == 'vgg16':\n",
        "\n",
        "        if method == 'm1':\n",
        "            aux_convs = \\\n",
        "                AuxiliaryConvolutions.AuxiliaryConvolutions().to(device)\n",
        "            rescale_factors = nn.Parameter(torch.FloatTensor(1, 512, 1,\n",
        "                    1)).to(device)  # there are 512 channels in conv4_3_feats\n",
        "            (conv4_3_feats, conv7_feats) = model(img)\n",
        "\n",
        "            # Rescale conv4_3 after L2 norm\n",
        "\n",
        "            norm = conv4_3_feats.pow(2).sum(dim=1, keepdim=True).sqrt()  # (N, 1, 38, 38)\n",
        "            conv4_3_feats = conv4_3_feats / norm  # (N, 512, 38, 38)\n",
        "            conv4_3_feats = conv4_3_feats * rescale_factors  # (N, 512, 38, 38)\n",
        "\n",
        "            # (PyTorch autobroadcasts singleton dimensions during arithmetic)\n",
        "\n",
        "            # Run auxiliary convolutions (higher level feature map generators)\n",
        "\n",
        "            (conv8_2_feats, conv9_2_feats, conv10_2_feats,\n",
        "             conv11_2_feats) = aux_convs(conv7_feats)  # (N, 512, 10, 10),  (N, 256, 5, 5), (N, 256, 3, 3), (N, 256, 1, 1)\n",
        "\n",
        "            # flatten feature vectors obtained at different layers\n",
        "\n",
        "            conv4_3_feats = torch.flatten(conv4_3_feats, start_dim=1)\n",
        "            conv7_feats = torch.flatten(conv7_feats, start_dim=1)\n",
        "            conv8_2_feats = torch.flatten(conv8_2_feats, start_dim=1)\n",
        "            conv9_2_feats = torch.flatten(conv9_2_feats, start_dim=1)\n",
        "            conv10_2_feats = torch.flatten(conv10_2_feats, start_dim=1)\n",
        "            conv11_2_feats = torch.flatten(conv11_2_feats, start_dim=1)\n",
        "\n",
        "            # Concatenate the feature vectors to obtain a final feature representation of the image\n",
        "\n",
        "            x = torch.cat([\n",
        "                conv4_3_feats,\n",
        "                conv7_feats,\n",
        "                conv8_2_feats,\n",
        "                conv9_2_feats,\n",
        "                conv10_2_feats,\n",
        "                conv11_2_feats,\n",
        "                ], dim=1)\n",
        "             \n",
        "        elif method == 'm2':\n",
        "\n",
        "            # Get features part of the network\n",
        "\n",
        "            model_features = model.features\n",
        "\n",
        "            x = model_features(img)\n",
        "            x = model.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = model.classifier[0](x)  # only first classifier layer\n",
        "    return x"
      ],
      "metadata": {
        "id": "ZsAdYpm0D3vV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster(X, n_clusters, algo='kmeans'):\n",
        "    if algo=='kmeans':\n",
        "        kmeans = MiniBatchKMeans(n_clusters, random_state=0, batch_size=128).fit(X)\n",
        "        return kmeans.labels_, kmeans.cluster_centers_ "
      ],
      "metadata": {
        "id": "YClV_03DPiG0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_dim(X, method='TSNE', dim=2):\n",
        "    if method=='TSNE':\n",
        "        transform = TSNE\n",
        "        trans = transform(n_components=dim) \n",
        "        Xreduced = trans.fit_transform(X) \n",
        "    return Xreduced"
      ],
      "metadata": {
        "id": "UiwTAcp6IAHf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "i57VXoTrSpDG"
      },
      "outputs": [],
      "source": [
        "def plot_(x,y1,y2,row,col,ind,title,xlabel,ylabel,label,isimage=False,color='b'):\n",
        "\n",
        "    \"\"\"\n",
        "    This function is used for plotting images and graphs (Visualization of end results of model training)\n",
        "    Arguments:\n",
        "    x - (np.ndarray or list) - an image array\n",
        "    y1 - (list) - for plotting graph on left side.\n",
        "    y2 - (list) - for plotting graph on right side.\n",
        "    row - (int) - row number of subplot \n",
        "    col - (int) - column number of subplot\n",
        "    ind - (int) - index number of subplot\n",
        "    title - (string) - title of the plot \n",
        "    xlabel - (list) - labels of x axis\n",
        "    ylabel - (list) - labels of y axis\n",
        "    label - (string) - for adding legend in the plot\n",
        "    isimage - (boolean) - True in case of image else False\n",
        "    color - (char) - color of the plot (prefered green for training and red for testing).\n",
        "    \"\"\"\n",
        "    \n",
        "    plt.subplot(row,col,ind)\n",
        "    if isimage:\n",
        "        plt.imshow(x)\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        plt.plot(y1,label=label,color='g'); plt.scatter(x,y1,color='g')\n",
        "        if y2!='': plt.plot(y2,color=color,label='validation'); plt.scatter(x,y2,color=color)\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ShowClusterIMG(img_folder_path, img_file_paths, clusterID, cluster_labels, n_images=5, save_img=False):\n",
        "  iter=0\n",
        "  plt.figure(figsize=(13,3))\n",
        "  for i,iterator in enumerate(cluster_labels):\n",
        "      if iterator == clusterID:\n",
        "          img = cv2.imread(img_folder_path+'/'+img_file_paths[i])\n",
        "          img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "          plot_(img,\"\",\"\",1,n_images,iter+1,\"cluster=\"+str(clusterID),\"\",\"\",\"\",True)\n",
        "          iter+=1\n",
        "      if iter>=n_images: break\n",
        "  if save_img:\n",
        "    plt.savefig(f'clustered{clusterID}_images.png', bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "AZ0QuNnJQTWd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, train_dl, valid_dl, EPOCH, print_feq):\n",
        "\n",
        "    for epoch in range(1, EPOCH + 1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "\n",
        "        for step, (img, boxes, labels) in enumerate(train_dl):\n",
        "            time_1 = time.time()\n",
        "            img = img.cuda()\n",
        "            \n",
        "            # boxes = torch.cat((boxes), dim=0)\n",
        "            boxes = [box.cuda() for box in boxes]\n",
        "            # labels = torch.cat((labels), dim=0)\n",
        "            labels = [label.cuda() for label in labels]\n",
        "\n",
        "            pred_loc, pred_sco = model(img)\n",
        "\n",
        "            loss = criterion(pred_loc, pred_sco, boxes, labels)\n",
        "\n",
        "            # Backward prop.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # losses.update(loss.item(), images.size(0))\n",
        "            train_loss.append(loss.item())\n",
        "            if step % print_feq == 0:\n",
        "                print(\n",
        "                    \"epoch:\",\n",
        "                    epoch,\n",
        "                    \"\\tstep:\",\n",
        "                    step + 1,\n",
        "                    \"/\",\n",
        "                    len(train_dl) + 1,\n",
        "                    \"\\ttrain loss:\",\n",
        "                    \"{:.4f}\".format(loss.item()),\n",
        "                    \"\\ttime:\",\n",
        "                    \"{:.4f}\".format((time.time() - time_1) * print_feq),\n",
        "                    \"s\",\n",
        "                )\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = []\n",
        "        for step, (img, boxes, labels) in enumerate(tqdm(valid_dl)):\n",
        "            img = img.cuda()\n",
        "            boxes = [box.cuda() for box in boxes]\n",
        "            labels = [label.cuda() for label in labels]\n",
        "            pred_loc, pred_sco = model(img)\n",
        "            loss = criterion(pred_loc, pred_sco, boxes, labels)\n",
        "            valid_loss.append(loss.item())\n",
        "\n",
        "        print(\n",
        "            \"epoch:\",\n",
        "            epoch,\n",
        "            \"/\",\n",
        "            EPOCH + 1,\n",
        "            \"\\ttrain loss:\",\n",
        "            \"{:.4f}\".format(np.mean(train_loss)),\n",
        "            \"\\tvalid loss:\",\n",
        "            \"{:.4f}\".format(np.mean(valid_loss)),\n",
        "        )\n",
        "\n",
        "    return np.mean(valid_loss)"
      ],
      "metadata": {
        "id": "afpqJROsZWl8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAIN"
      ],
      "metadata": {
        "id": "tYVrhW0USN9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(\n",
        "    download=True,\n",
        "    n_clusters=22,\n",
        "    n_data=500,\n",
        "    method=\"m1\",\n",
        "    img_folder_path=\"/content/data/VOCdevkit/VOC2012/JPEGImages\",\n",
        "    annotation_folder_path=\"/content/data/VOCdevkit/VOC2012/Annotations\",\n",
        "    cluster_visualization=False,\n",
        "    ToTrain=True,\n",
        "    TrainWithClustering=True,\n",
        "    min_cluster_size = 5,\n",
        "    split_size=0.8,\n",
        "    n_classes=21,\n",
        "    EPOCH=5,\n",
        "    print_feq=100,\n",
        "    LR=1e-3,\n",
        "    BS=4,\n",
        "    momentum=0.9,\n",
        "    weight_decay=5e-4,\n",
        "):\n",
        "    \"\"\"\n",
        "    main function \n",
        "    \n",
        "    Arguments:\n",
        "        download - (bool, default=True) - To download the data\n",
        "        n_clusters - (int, default=22) - No. of clusters\n",
        "        n_data - (int, default=500) -  No. of data to sample from whole set\n",
        "        method - (str, default='m1') -  different methods for feature extraction\n",
        "        img_folder_path - (str) -  path to directory of images\n",
        "        annotation_folder_path - (str) - path to directory of annotations\n",
        "        cluster_visualization - (bool, default=False): to perform visualization of clusters\n",
        "        train - (bool, default=True) - to perform training\n",
        "        TrainWithClustering - (bool, default=True) - to train with partitioning the data  \n",
        "        min_cluster_size - (int, default=5) - minimum cluster size for training to be performed\n",
        "        split_size - (float, default=0.8) - split % for train & val\n",
        "        n_classes - (int, default=21) - No. of classes in the data labels\n",
        "        EPOCH - (int, default=5) - no. of epochs \n",
        "        LR - (float, default=1e-3) - Learning Rate\n",
        "        BS - (float, default=4) - batch size \n",
        "        momentum - (float, default=0.9) - momentum while optimizing through Adam\n",
        "        weight_decay - (float, default=5e-4) - weight decay \n",
        "    \"\"\"\n",
        "\n",
        "    # --------------DATASET PREP--------------\n",
        "    downloadVOC(download=download)  # downloads the VOCDataset\n",
        "\n",
        "    # label map dict\n",
        "    label_map = readURL(\n",
        "        \"https://raw.githubusercontent.com/harshraj172/SSD_clustering/main/data/PascalVOC/label_map.json\"\n",
        "    )\n",
        "    rev_label_map = readURL(\n",
        "        \"https://raw.githubusercontent.com/harshraj172/SSD_clustering/main/data/PascalVOC/rev_label_map.json\"\n",
        "    )\n",
        "\n",
        "    # sample n file(imgs) from the Dataset\n",
        "    img_file_paths = SampleFromData(img_folder_path=img_folder_path, n=n_data)\n",
        "\n",
        "    # Dataset & Dataloader\n",
        "    ds = SSDDataset(\n",
        "        file_folder=img_file_paths,\n",
        "        img_folder_path=img_folder_path,\n",
        "        annotation_folder_path=annotation_folder_path,\n",
        "        label_map=label_map,\n",
        "        transform=transformIMG(),\n",
        "    )\n",
        "    dl = DataLoader(ds, batch_size=BS, collate_fn=ds.collate_fn)\n",
        "\n",
        "\n",
        "    # --------------EXTRACT FEATURES--------------\n",
        "    X_encoded = []\n",
        "    if method == \"m1\":\n",
        "        model = base_model.VGGBase().to(device)\n",
        "    elif method == \"m2\":\n",
        "        model = models.vgg16(pretrained=True).to(device)\n",
        "\n",
        "    for i, (img, boxes, label) in enumerate(dl):\n",
        "        img = img.to(device)\n",
        "        x = extractFeatures(img=img, model=model, method=method)\n",
        "        X_encoded.extend(x.cpu().detach().numpy())\n",
        "    X_encoded = np.array(X_encoded)\n",
        "\n",
        "\n",
        "    # --------------CLUSTERING & VISUALIZATION--------------\n",
        "    X_reduced = reduce_dim(X_encoded)  # reduce dim\n",
        "    cluster_labels, centroids = cluster(\n",
        "        X=X_encoded, n_clusters=n_clusters\n",
        "    )  # clustering\n",
        "\n",
        "    # Visualization\n",
        "    if cluster_visualization:\n",
        "        print(\"if Number of clusters: \" + str(n_clusters))\n",
        "        print(\"-------------------------------\")\n",
        "        print(\"-------------------------------\")\n",
        "\n",
        "        # Clustering\n",
        "        cluster_labels, centroids = cluster(X=X_encoded, n_clusters=n_clusters)\n",
        "\n",
        "        # Scatter Plot\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 1, 1)\n",
        "        plt.scatter(\n",
        "            X_reduced[:, 0],\n",
        "            X_reduced[:, 1],\n",
        "            c=cluster_labels.astype(float),\n",
        "            s=50,\n",
        "            alpha=0.5,\n",
        "        )\n",
        "        # plt.scatter(centroids[:, 0], centroids[:, 1], c=None, s=50)\n",
        "        plt.show()\n",
        "\n",
        "        # Show atmost n_images images per cluster\n",
        "        for row in range(n_clusters):\n",
        "            ShowClusterIMG(\n",
        "                img_folder_path=img_folder_path,\n",
        "                img_file_paths=img_file_paths,\n",
        "                clusterID=row,\n",
        "                cluster_labels=cluster_labels,\n",
        "            )\n",
        "            print()\n",
        "\n",
        "\n",
        "    # --------------TRAIN SSD--------------\n",
        "    if ToTrain:\n",
        "\n",
        "        img_file_paths = np.array(img_file_paths)\n",
        "        cluster_labels = np.array(cluster_labels)\n",
        "      \n",
        "        if TrainWithClustering:\n",
        "\n",
        "            valid_loss_lst = []\n",
        "            # define the list models with each cluster data passed to different model\n",
        "            model_list = nn.ModuleList(\n",
        "                [ssd.SSD(n_classes).to(device) for i in range(n_clusters)]\n",
        "            )\n",
        "\n",
        "            for cluster_id in np.unique(cluster_labels):\n",
        "\n",
        "                img_name = img_file_paths[(cluster_labels == cluster_id)]\n",
        "                print(f\"Number of images in cluster {cluster_id} = {len(img_name)}\")\n",
        "\n",
        "                # if number of data in cluster is more than min_cluster_size\n",
        "                if len(img_name) > min_cluster_size:\n",
        "\n",
        "                    model = model_list[cluster_id]\n",
        "                    criterion = Loss.MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(\n",
        "                        device\n",
        "                    )\n",
        "                    optimizer = torch.optim.SGD(\n",
        "                        model.parameters(),\n",
        "                        lr=LR,\n",
        "                        momentum=momentum,\n",
        "                        weight_decay=weight_decay,\n",
        "                    )\n",
        "\n",
        "                    # partition data after clustering\n",
        "                    train_img_name = img_name[: int(len(img_name) * split_size)]\n",
        "                    valid_img_name = img_name[int(len(img_name) * split_size) :]\n",
        "\n",
        "                    # train dataset\n",
        "                    train_ds = SSDDataset(\n",
        "                        train_img_name,\n",
        "                        img_folder_path=img_folder_path,\n",
        "                        annotation_folder_path=annotation_folder_path,\n",
        "                        label_map=label_map,\n",
        "                        transform=transformIMG(),\n",
        "                    )\n",
        "                    train_dl = DataLoader(\n",
        "                        train_ds, batch_size=BS, collate_fn=train_ds.collate_fn\n",
        "                    )\n",
        "\n",
        "                    # valid dataset\n",
        "                    valid_ds = SSDDataset(\n",
        "                        valid_img_name,\n",
        "                        img_folder_path=img_folder_path,\n",
        "                        annotation_folder_path=annotation_folder_path,\n",
        "                        label_map=label_map,\n",
        "                        transform=transformIMG(),\n",
        "                    )\n",
        "                    valid_dl = DataLoader(\n",
        "                        valid_ds, batch_size=BS, collate_fn=valid_ds.collate_fn\n",
        "                    )\n",
        "\n",
        "                    # start training\n",
        "                    valid_loss_lst.append(train(\n",
        "                        model, criterion, optimizer, train_dl, valid_dl, EPOCH, print_feq\n",
        "                    ))\n",
        "\n",
        "                    print()\n",
        "                    print(f\"Finished Training for model number {cluster_id}\")\n",
        "                    print(f\"-------------------------------------------------\")\n",
        "                    print(f\"-------------------------------------------------\")\n",
        "                    print()\n",
        "                    print()\n",
        "            \n",
        "            print(f\"-----------------Average Valid Loss = {np.mean(valid_loss_lst)}-----------------\")    \n",
        "\n",
        "        else:\n",
        "            model = ssd.SSD(n_classes).to(device)\n",
        "            criterion = Loss.MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(device)\n",
        "            optimizer = torch.optim.SGD(\n",
        "                model.parameters(),\n",
        "                lr=LR,\n",
        "                momentum=momentum,\n",
        "                weight_decay=weight_decay,\n",
        "            )\n",
        "\n",
        "            # partition data after clustering\n",
        "            train_img_name = img_file_paths[: int(len(img_file_paths) * split_size)]\n",
        "            valid_img_name = img_file_paths[int(len(img_file_paths) * split_size) :]\n",
        "\n",
        "            # train dataset\n",
        "            train_ds = SSDDataset(\n",
        "                train_img_name,\n",
        "                img_folder_path=img_folder_path,\n",
        "                annotation_folder_path=annotation_folder_path,\n",
        "                label_map=label_map,\n",
        "                transform=transformIMG(),\n",
        "            )\n",
        "            train_dl = DataLoader(\n",
        "                train_ds, batch_size=BS, collate_fn=train_ds.collate_fn\n",
        "            )\n",
        "\n",
        "            # valid dataset\n",
        "            valid_ds = SSDDataset(\n",
        "                valid_img_name,\n",
        "                img_folder_path=img_folder_path,\n",
        "                annotation_folder_path=annotation_folder_path,\n",
        "                label_map=label_map,\n",
        "                transform=transformIMG(),\n",
        "            )\n",
        "            valid_dl = DataLoader(\n",
        "                valid_ds, batch_size=BS, collate_fn=valid_ds.collate_fn\n",
        "            )\n",
        "\n",
        "            # start training\n",
        "            valid_loss = train(\n",
        "                model, criterion, optimizer, train_dl, valid_dl, EPOCH, print_feq\n",
        "            )\n",
        "            print()\n",
        "            print(f\"Finished Training for model\")\n",
        "            print(f\"-------------------------------------------------\")\n",
        "            print(f\"-------------------------------------------------\")\n",
        "            print()\n",
        "            print()"
      ],
      "metadata": {
        "id": "JwkdyKMK-C_z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# __name__\n",
        "if __name__==\"__main__\":\n",
        "  device = onceInit(kCUDA=True)  # get the device and init random seed\n",
        "\n",
        "  # run 10 iter to track non-deterministism\n",
        "  for _ in range(2):\n",
        "    main(download=True, method='m2', cluster_visualization=True, n_data=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mesJyPW4BuwN",
        "outputId": "091cd7c2-9b85-4c9d-d425-73603c550db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchutils.onceInit device = cuda:0\n",
            "initSeeds(1)\n",
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SSD_Clustering4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}