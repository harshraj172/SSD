{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project\n",
        "* **Aim:** To validate the performance of **Single-Shot-Detection** when the data is clustered and each cluster is used to train a separate model. \n",
        "* **Process overview:**\n",
        "    1. Download PascalVOC Dataset of the year 2012(you can download others). \n",
        "    2. Use Pretrained *VGG-16 model* to get the feature vector of images in the data.\n",
        "    3. Cluster the images based on their feature vectors by MiniBatchKMeans(to avoid RAM Crash).\n",
        "    4. Initialize num_clusters no. of SSD models, training each with a different set of data(data from each clusters).\n",
        "    5. Train a SSD model with the whole data.\n",
        "    6. Validate the difference in performance between the two approaches\n"
      ],
      "metadata": {
        "id": "I06doxoCE8wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/harshraj172/SSD_clustering.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plHkdlquSA31",
        "outputId": "37126a72-2c04-4b72-da94-554ae91945bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SSD_clustering'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (210/210), done.\u001b[K\n",
            "remote: Total 228 (delta 78), reused 6 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (228/228), 98.95 KiB | 16.49 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GQTx78V4Hk3t"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# For commands\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "os.chdir('/content/')\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For visualization\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import imageio as io\n",
        "from pylab import *\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "#For model performance\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cdist\n",
        "import joblib\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "\n",
        "# For array manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.util.testing as tm\n",
        "import os\n",
        "import random\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from SSD_clustering.data.PascalVOC.Dataset import SSDDataset\n",
        "from SSD_clustering.utils.utils import *\n",
        "from SSD_clustering.utils import AuxiliaryConvolutions, PredictionConvolutions, Loss\n",
        "from SSD_clustering.model import ssd, base_model"
      ],
      "metadata": {
        "id": "c3ns7OR-9Bg-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initSeeds(seed=1):\n",
        "\tprint(f\"initSeeds({seed})\")\n",
        "\trandom.seed(seed)\n",
        "\ttorch.manual_seed(seed) \t#turn on this 2 lines when torch is being used\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\tnp.random.seed(seed)"
      ],
      "metadata": {
        "id": "pi-T0F6No_V4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cuda(cudadevice='cuda:0'):\n",
        "\t\"\"\" return the best Cuda device \"\"\"\n",
        "\tdevid = cudadevice\n",
        "\t#print ('Current cuda device ', devid, torch.cuda.get_device_name(devid))\n",
        "\t#device = 'cuda:0'\t#most of the time torch choose the right CUDA device\n",
        "\treturn torch.device(devid)\t\t#use this device object instead of the device string"
      ],
      "metadata": {
        "id": "ru5nv1LFP5NZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onceInit(kCUDA=False, cudadevice='cuda:0', seed=1):\n",
        "\t#print(f\"onceInit {cudadevice}\")\n",
        "\tif kCUDA and torch.cuda.is_available():\n",
        "\t\tif cudadevice is None:\n",
        "\t\t\tdevice = get_cuda()\n",
        "\t\telse:\n",
        "\t\t\tdevice = torch.device(cudadevice)\n",
        "\t\t\ttorch.cuda.set_device(device)\n",
        "\telse:\n",
        "\t\tdevice = 'cpu'\n",
        "\n",
        "\tprint(f\"torchutils.onceInit device = {device}\")\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\ttorch.backends.cudnn.enabled = kCUDA\n",
        "\n",
        "\tinitSeeds(seed)\n",
        "\n",
        "\treturn device"
      ],
      "metadata": {
        "id": "3ZlVNw7bpiLC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MVEhsvHiHm1-"
      },
      "outputs": [],
      "source": [
        "def downloadVOC(save_path='./data/', year='2012', download=True):\n",
        "  \"\"\"downloads the PascalVOC Dataset\"\"\"\n",
        "  datasets.VOCDetection(root=save_path, year=year, download=download, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ABg_vr-NH1Nt"
      },
      "outputs": [],
      "source": [
        "def transformIMG(imgsize=300, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "  \"\"\"Resize the raw image, Normalize it\"\"\"\n",
        "  tsfm = transforms.Compose([\n",
        "      transforms.Resize([imgsize, imgsize]),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean, std),\n",
        "  ])\n",
        "  return tsfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SampleFromData(img_folder_path, n:int):\n",
        "  \"\"\"Sample img path from the full list of images\"\"\"\n",
        "  imgFile_names = []\n",
        "  for file_ in os.listdir(img_folder_path):\n",
        "    imgFile_names.append(file_)\n",
        "  \n",
        "  imgFile_names.sort()\n",
        "\n",
        "  # return random.sample(imgFile_names, n)\n",
        "  return imgFile_names[:n]"
      ],
      "metadata": {
        "id": "RcgTsaoWt08y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readURL(url):\n",
        "  resp = requests.get(url)\n",
        "  data = json.loads(resp.text)\n",
        "  return data"
      ],
      "metadata": {
        "id": "sRAKfqdy1mjd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auxiliary Convolutions**\n",
        "\n",
        "It is used as the additional transformation of the feature vector generated through base model which is then used in concatenation with the former."
      ],
      "metadata": {
        "id": "jr-9WTDCc5zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extractFeatures(\n",
        "    imgs,\n",
        "    model,\n",
        "    model_name='vgg16',\n",
        "    method='m1',\n",
        "    ):\n",
        "    \"\"\"\n",
        "  Different ways for feature extraction to be used in Clustering\n",
        "  Arguments:\n",
        "  imgs((int, int, int)): batch of images(batch_size, imgsize, imgsize)\n",
        "  model: loaded model for feature extraction\n",
        "  model_name(str, optional): the model to use for feature extraction\n",
        "  method(str, optional): different methods tried for feature extraction\n",
        "                         m1-> the features are extracted in the same way as is done by the base_model in SSD\n",
        "                         m2-> takes the last layer output of the model, does avgPooling and passes through \n",
        "                              the first layer of the classifier architecture\n",
        "  \"\"\"\n",
        "\n",
        "    if model_name == 'vgg16':\n",
        "\n",
        "        if method == 'm1':\n",
        "            aux_convs = \\\n",
        "                AuxiliaryConvolutions.AuxiliaryConvolutions().to(device)\n",
        "            rescale_factors = nn.Parameter(torch.FloatTensor(1, 512, 1,\n",
        "                    1)).to(device)  # there are 512 channels in conv4_3_feats\n",
        "            (conv4_3_feats, conv7_feats) = model(imgs)\n",
        "\n",
        "            # Rescale conv4_3 after L2 norm\n",
        "\n",
        "            norm = conv4_3_feats.pow(2).sum(dim=1, keepdim=True).sqrt()  # (N, 1, 38, 38)\n",
        "            conv4_3_feats = conv4_3_feats / norm  # (N, 512, 38, 38)\n",
        "            conv4_3_feats = conv4_3_feats * rescale_factors  # (N, 512, 38, 38)\n",
        "\n",
        "            # (PyTorch autobroadcasts singleton dimensions during arithmetic)\n",
        "\n",
        "            # Run auxiliary convolutions (higher level feature map generators)\n",
        "\n",
        "            (conv8_2_feats, conv9_2_feats, conv10_2_feats,\n",
        "             conv11_2_feats) = aux_convs(conv7_feats)  # (N, 512, 10, 10),  (N, 256, 5, 5), (N, 256, 3, 3), (N, 256, 1, 1)\n",
        "\n",
        "            # flatten feature vectors obtained at different layers\n",
        "\n",
        "            conv4_3_feats = torch.flatten(conv4_3_feats, start_dim=1)\n",
        "            conv7_feats = torch.flatten(conv7_feats, start_dim=1)\n",
        "            conv8_2_feats = torch.flatten(conv8_2_feats, start_dim=1)\n",
        "            conv9_2_feats = torch.flatten(conv9_2_feats, start_dim=1)\n",
        "            conv10_2_feats = torch.flatten(conv10_2_feats, start_dim=1)\n",
        "            conv11_2_feats = torch.flatten(conv11_2_feats, start_dim=1)\n",
        "\n",
        "            # Concatenate the feature vectors to obtain a final feature representation of the image\n",
        "\n",
        "            x = torch.cat([\n",
        "                conv4_3_feats,\n",
        "                conv7_feats,\n",
        "                conv8_2_feats,\n",
        "                conv9_2_feats,\n",
        "                conv10_2_feats,\n",
        "                conv11_2_feats,\n",
        "                ], dim=1)\n",
        "             \n",
        "        elif method == 'm2':\n",
        "          \n",
        "            # Get features part of the network\n",
        "\n",
        "            model_features = model.features\n",
        "\n",
        "            x = model_features(imgs)\n",
        "            x = model.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = model.classifier[0](x)  # only first classifier layer\n",
        "    return x"
      ],
      "metadata": {
        "id": "ZsAdYpm0D3vV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster(X, n_clusters, algo='kmeans'):\n",
        "    if algo=='kmeans':\n",
        "        kmeans = MiniBatchKMeans(n_clusters, random_state=0, batch_size=128).fit(X)\n",
        "        return kmeans.labels_, kmeans.cluster_centers_ "
      ],
      "metadata": {
        "id": "YClV_03DPiG0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_dim(X, method='TSNE', dim=2):\n",
        "    if method=='TSNE':\n",
        "        transform = TSNE\n",
        "        trans = transform(n_components=dim) \n",
        "        Xreduced = trans.fit_transform(X) \n",
        "    return Xreduced"
      ],
      "metadata": {
        "id": "UiwTAcp6IAHf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i57VXoTrSpDG"
      },
      "outputs": [],
      "source": [
        "def plot_(x,y1,y2,row,col,ind,title,xlabel,ylabel,label,isimage=False,color='b'):\n",
        "\n",
        "    \"\"\"\n",
        "    This function is used for plotting images and graphs (Visualization of end results of model training)\n",
        "    Arguments:\n",
        "    x - (np.ndarray or list) - an image array\n",
        "    y1 - (list) - for plotting graph on left side.\n",
        "    y2 - (list) - for plotting graph on right side.\n",
        "    row - (int) - row number of subplot \n",
        "    col - (int) - column number of subplot\n",
        "    ind - (int) - index number of subplot\n",
        "    title - (string) - title of the plot \n",
        "    xlabel - (list) - labels of x axis\n",
        "    ylabel - (list) - labels of y axis\n",
        "    label - (string) - for adding legend in the plot\n",
        "    isimage - (boolean) - True in case of image else False\n",
        "    color - (char) - color of the plot (prefered green for training and red for testing).\n",
        "    \"\"\"\n",
        "    \n",
        "    plt.subplot(row,col,ind)\n",
        "    if isimage:\n",
        "        plt.imshow(x)\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        plt.plot(y1,label=label,color='g'); plt.scatter(x,y1,color='g')\n",
        "        if y2!='': plt.plot(y2,color=color,label='validation'); plt.scatter(x,y2,color=color)\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ShowClusterIMG(img_folder_path, img_file_paths, clusterID, cluster_labels, n_images=5, save_img=False):\n",
        "  iter=0\n",
        "  plt.figure(figsize=(13,3))\n",
        "  for i,iterator in enumerate(cluster_labels):\n",
        "      if iterator == clusterID:\n",
        "          img = cv2.imread(img_folder_path+'/'+img_file_paths[i])\n",
        "          img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "          plot_(img,\"\",\"\",1,n_images,iter+1,\"cluster=\"+str(clusterID),\"\",\"\",\"\",True)\n",
        "          iter+=1\n",
        "      if iter>=n_images: break\n",
        "  if save_img:\n",
        "    plt.savefig(f'clustered{clusterID}_images.png', bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "AZ0QuNnJQTWd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gini(array):\n",
        "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
        "    array = np.array(array)\n",
        "    Pi = [np.count_nonzero(array == ele)/len(array) for ele in np.unique(array)]\n",
        "    return (1 - sum(i*i for i in Pi))"
      ],
      "metadata": {
        "id": "AlYko9sCdQ52"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, train_dl, valid_dl, EPOCH, print_feq):\n",
        "    valid_loss_per_epoch = []\n",
        "\n",
        "    for epoch in range(1, EPOCH + 1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "\n",
        "        for step, (imgs, boxes, labels) in enumerate(train_dl):\n",
        "            time_1 = time.time()\n",
        "            imgs = imgs.to(device)\n",
        "            \n",
        "            # boxes = torch.cat((boxes), dim=0)\n",
        "            boxes = [box.to(device) for box in boxes]\n",
        "            # labels = torch.cat((labels), dim=0)\n",
        "            labels = [label.to(device) for label in labels]\n",
        "\n",
        "            pred_loc, pred_sco = model(imgs)\n",
        "\n",
        "            loss = criterion(pred_loc, pred_sco, boxes, labels)\n",
        "\n",
        "            # Backward prop.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # losses.update(loss.item(), images.size(0))\n",
        "            train_loss.append(loss.item())\n",
        "            if step % print_feq == 0:\n",
        "                print(\n",
        "                    \"epoch:\",\n",
        "                    epoch,\n",
        "                    \"\\tstep:\",\n",
        "                    step + 1,\n",
        "                    \"/\",\n",
        "                    len(train_dl) + 1,\n",
        "                    \"\\ttrain loss:\",\n",
        "                    \"{:.4f}\".format(loss.item()),\n",
        "                    \"\\ttime:\",\n",
        "                    \"{:.4f}\".format((time.time() - time_1) * print_feq),\n",
        "                    \"s\",\n",
        "                )\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = []\n",
        "        for step, (imgs, boxes, labels) in enumerate(tqdm(valid_dl)):\n",
        "            imgs = imgs.to(device)\n",
        "            boxes = [box.to(device) for box in boxes]\n",
        "            labels = [label.to(device) for label in labels]\n",
        "            pred_loc, pred_sco = model(imgs)\n",
        "            loss = criterion(pred_loc, pred_sco, boxes, labels)\n",
        "            valid_loss.append(loss.item())\n",
        "        \n",
        "        valid_loss_per_epoch.append(np.mean(valid_loss))\n",
        "\n",
        "        print(\n",
        "            \"epoch:\",\n",
        "            epoch,\n",
        "            \"/\",\n",
        "            EPOCH + 1,\n",
        "            \"\\ttrain loss:\",\n",
        "            \"{:.4f}\".format(np.mean(train_loss)),\n",
        "            \"\\tvalid loss:\",\n",
        "            \"{:.4f}\".format(np.mean(valid_loss)),\n",
        "        )\n",
        "\n",
        "    return np.mean(valid_loss_per_epoch)"
      ],
      "metadata": {
        "id": "afpqJROsZWl8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(download, img_folder_path, annotation_folder_path, n_data=500, method='m1'):\n",
        "  \"\"\"\n",
        "  download - (bool, default=True) - To download the data\n",
        "  img_folder_path - (str) -  path to directory of images\n",
        "  annotation_folder_path - (str) - path to directory of annotations\n",
        "  n_data - (int, default=500) -  No. of data to sample from whole set\n",
        "  docluster - (bool, default=True) - to train with partitioning the data\n",
        "  method - (str, default='m1') -  different methods for feature extraction\n",
        "  \"\"\"\n",
        "  # --------------DATASET PREP--------------\n",
        "  downloadVOC(download=download)  # downloads the VOCDataset\n",
        "\n",
        "  # label map dict\n",
        "  label_map = readURL(\n",
        "      \"https://raw.githubusercontent.com/harshraj172/SSD_clustering/main/data/PascalVOC/label_map.json\"\n",
        "  )\n",
        "  # rev_label_map = readURL(\n",
        "  #     \"https://raw.githubusercontent.com/harshraj172/SSD_clustering/main/data/PascalVOC/rev_label_map.json\"\n",
        "  # )\n",
        "\n",
        "  # sample n file(imgs) from the Dataset\n",
        "  img_file_paths = SampleFromData(img_folder_path=img_folder_path, n=n_data)  # constant order\n",
        "\n",
        "  # Dataset & Dataloader\n",
        "  ds = SSDDataset(\n",
        "      file_folder=img_file_paths,\n",
        "      img_folder_path=img_folder_path,\n",
        "      annotation_folder_path=annotation_folder_path,\n",
        "      label_map=label_map,\n",
        "      transform=transformIMG(),\n",
        "  )\n",
        "  dl = DataLoader(ds, batch_size=BS, collate_fn=ds.collate_fn)\n",
        "\n",
        "  # --------------EXTRACT FEATURES--------------\n",
        "  X_encoded = []\n",
        "  if method == \"m1\":\n",
        "      model = base_model.VGGBase().to(device)\n",
        "  elif method == \"m2\":\n",
        "      model = models.vgg16(pretrained=True).to(device)\n",
        "\n",
        "  class_labels = []\n",
        "  for i, (imgs, boxes, labels) in enumerate(dl):\n",
        "      class_labels.extend(\n",
        "          [float(max(set(label), key=list(label).count)) for label in labels]\n",
        "      )  # among various labels take label with highest frequency\n",
        "      imgs = imgs.to(device)\n",
        "      x = extractFeatures(imgs=imgs, model=model, method=method)\n",
        "      X_encoded.extend(x.cpu().detach().numpy())\n",
        "\n",
        "  class_labels = np.array(class_labels)\n",
        "  X_encoded = np.array(X_encoded)\n",
        "\n",
        "  return img_file_paths, label_map, class_labels, X_encoded"
      ],
      "metadata": {
        "id": "GaQcK0Js8rfe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clusterANDvisual(X_encoded, img_file_paths, img_folder_path, n_clusters=22, cluster_visualization=True):\n",
        "\n",
        "  \"\"\"\n",
        "  img_folder_path - (str) -  path to directory of images\n",
        "  \"\"\"\n",
        "\n",
        "  # --------------CLUSTERING & VISUALIZATION--------------\n",
        "  X_reduced = reduce_dim(X_encoded)  # reduce dim\n",
        "  cluster_labels, centroids = cluster(\n",
        "      X=X_encoded, n_clusters=n_clusters\n",
        "  )  # clustering\n",
        "  cluster_labels = np.array(cluster_labels)\n",
        "\n",
        "  # Visualization\n",
        "  if cluster_visualization:\n",
        "      print(\"if Number of clusters: \" + str(n_clusters))\n",
        "      print(\"-------------------------------\")\n",
        "      print(\"-------------------------------\")\n",
        "\n",
        "      # Scatter Plot\n",
        "      plt.figure(figsize=(10, 5))\n",
        "      plt.subplot(1, 1, 1)\n",
        "      plt.scatter(\n",
        "          X_reduced[:, 0],\n",
        "          X_reduced[:, 1],\n",
        "          c=cluster_labels.astype(float),\n",
        "          s=50,\n",
        "          alpha=0.5,\n",
        "      )\n",
        "      plt.scatter(centroids[:, 0], centroids[:, 1], c=None, s=50)\n",
        "      plt.show()\n",
        "\n",
        "      # Show atmost n_images images per cluster\n",
        "      for row in range(n_clusters):\n",
        "          ShowClusterIMG(\n",
        "              img_folder_path=img_folder_path,\n",
        "              img_file_paths=img_file_paths,\n",
        "              clusterID=row,\n",
        "              cluster_labels=cluster_labels,\n",
        "          )\n",
        "          print()\n",
        "  return cluster_labels"
      ],
      "metadata": {
        "id": "P0AeIgTK9oVp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainSSD(\n",
        "  img_file_paths, \n",
        "  class_labels,\n",
        "  cluster_labels,\n",
        "  label_map,\n",
        "  img_folder_path,\n",
        "  annotation_folder_path,\n",
        "  method='m1',\n",
        "  n_clusters=22,\n",
        "  TrainWithClustering=True,\n",
        "  min_cluster_size=5,\n",
        "  split_size=0.8,\n",
        "  n_classes=21,\n",
        "  EPOCH=5,\n",
        "  print_feq=100,\n",
        "  LR=1e-3,\n",
        "  BS=4,\n",
        "  momentum=0.9,\n",
        "  weight_decay=5e-4,\n",
        "): \n",
        "\n",
        "  analysis_df = pd.DataFrame(\n",
        "      columns=[\n",
        "          \"train_with_clustering\",\n",
        "          \"method(Clustering Feature Extraction)\",\n",
        "          \"Gini Index\",\n",
        "          \"mean Valid Loss\",\n",
        "          \"std Valid Loss\",\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # --------------TRAIN SSD--------------\n",
        "  img_file_paths = np.array(img_file_paths)\n",
        "\n",
        "  if TrainWithClustering:\n",
        "\n",
        "      valid_loss_per_clust = []\n",
        "      # define the list models with each cluster data passed to different model\n",
        "      model_list = nn.ModuleList(\n",
        "          [ssd.SSD(n_classes).to(device) for i in range(n_clusters)]\n",
        "      )\n",
        "\n",
        "      for cluster_id in np.unique(cluster_labels):\n",
        "\n",
        "          img_name = img_file_paths[(cluster_labels == cluster_id)]\n",
        "          print(f\"Number of images in cluster {cluster_id} = {len(img_name)}\")\n",
        "\n",
        "          # if number of data in cluster is more than min_cluster_size\n",
        "          if len(img_name) > min_cluster_size:\n",
        "\n",
        "              model = model_list[cluster_id]\n",
        "              criterion = Loss.MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(\n",
        "                  device\n",
        "              )\n",
        "              optimizer = torch.optim.SGD(\n",
        "                  model.parameters(),\n",
        "                  lr=LR,\n",
        "                  momentum=momentum,\n",
        "                  weight_decay=weight_decay,\n",
        "              )\n",
        "\n",
        "              # partition data after clustering\n",
        "              train_img_name = img_name[: int(len(img_name) * split_size)]\n",
        "              valid_img_name = img_name[int(len(img_name) * split_size) :]\n",
        "\n",
        "              # train dataset\n",
        "              train_ds = SSDDataset(\n",
        "                  train_img_name,\n",
        "                  img_folder_path=img_folder_path,\n",
        "                  annotation_folder_path=annotation_folder_path,\n",
        "                  label_map=label_map,\n",
        "                  transform=transformIMG(),\n",
        "              )\n",
        "              train_dl = DataLoader(\n",
        "                  train_ds, batch_size=BS, collate_fn=train_ds.collate_fn\n",
        "              )\n",
        "\n",
        "              # valid dataset\n",
        "              valid_ds = SSDDataset(\n",
        "                  valid_img_name,\n",
        "                  img_folder_path=img_folder_path,\n",
        "                  annotation_folder_path=annotation_folder_path,\n",
        "                  label_map=label_map,\n",
        "                  transform=transformIMG(),\n",
        "              )\n",
        "              valid_dl = DataLoader(\n",
        "                  valid_ds, batch_size=BS, collate_fn=valid_ds.collate_fn\n",
        "              )\n",
        "\n",
        "              # start training\n",
        "              valid_loss_per_clust.append(\n",
        "                  train(\n",
        "                      model,\n",
        "                      criterion,\n",
        "                      optimizer,\n",
        "                      train_dl,\n",
        "                      valid_dl,\n",
        "                      EPOCH,\n",
        "                      print_feq,\n",
        "                  )\n",
        "              )\n",
        "\n",
        "              print()\n",
        "              print(f\"Finished Training for model number {cluster_id}\")\n",
        "              print(f\"-------------------------------------------------\")\n",
        "              print(f\"-------------------------------------------------\")\n",
        "              print()\n",
        "              print()\n",
        "\n",
        "      analysis_df.loc[0, \"train_with_clustering\"] = 1\n",
        "      analysis_df.loc[0, \"method(Clustering Feature Extraction)\"] = method\n",
        "      analysis_df.loc[0, \"Gini Index\"] = np.mean(\n",
        "          [\n",
        "              gini(class_labels[(cluster_labels == cluster_id)])\n",
        "              for cluster_id in np.unique(cluster_labels)\n",
        "          ]\n",
        "      )\n",
        "      analysis_df.loc[0, \"max Valid Loss\"] = np.amax(valid_loss_per_clust)\n",
        "      analysis_df.loc[0, \"min Valid Loss\"] = np.amin(valid_loss_per_clust)\n",
        "      analysis_df.loc[0, \"mean Valid Loss\"] = np.mean(valid_loss_per_clust)\n",
        "      analysis_df.loc[0, \"std Valid Loss\"] = np.std(valid_loss_per_clust)\n",
        "\n",
        "  else:\n",
        "      model = ssd.SSD(n_classes).to(device)\n",
        "      criterion = Loss.MultiBoxLoss(priors_cxcy=model.priors_cxcy).to(device)\n",
        "      optimizer = torch.optim.SGD(\n",
        "          model.parameters(),\n",
        "          lr=LR,\n",
        "          momentum=momentum,\n",
        "          weight_decay=weight_decay,\n",
        "      )\n",
        "\n",
        "      # partition data after clustering\n",
        "      train_img_name = img_file_paths[: int(len(img_file_paths) * split_size)]\n",
        "      valid_img_name = img_file_paths[int(len(img_file_paths) * split_size) :]\n",
        "\n",
        "      # train dataset\n",
        "      train_ds = SSDDataset(\n",
        "          train_img_name,\n",
        "          img_folder_path=img_folder_path,\n",
        "          annotation_folder_path=annotation_folder_path,\n",
        "          label_map=label_map,\n",
        "          transform=transformIMG(),\n",
        "      )\n",
        "      train_dl = DataLoader(\n",
        "          train_ds, batch_size=BS, collate_fn=train_ds.collate_fn\n",
        "      )\n",
        "\n",
        "      # valid dataset\n",
        "      valid_ds = SSDDataset(\n",
        "          valid_img_name,\n",
        "          img_folder_path=img_folder_path,\n",
        "          annotation_folder_path=annotation_folder_path,\n",
        "          label_map=label_map,\n",
        "          transform=transformIMG(),\n",
        "      )\n",
        "      valid_dl = DataLoader(\n",
        "          valid_ds, batch_size=BS, collate_fn=valid_ds.collate_fn\n",
        "      )\n",
        "\n",
        "      # start training\n",
        "      valid_loss = train(\n",
        "          model, criterion, optimizer, train_dl, valid_dl, EPOCH, print_feq\n",
        "      )\n",
        "      analysis_df.loc[0, \"train_with_clustering\"] = 0\n",
        "      analysis_df.loc[0, \"method(Clustering Feature Extraction)\"] = \"\"\n",
        "      analysis_df.loc[0, \"Gini Index\"] = \"\"\n",
        "      analysis_df.loc[0, \"max Valid Loss\"] = \"\"\n",
        "      analysis_df.loc[0, \"min Valid Loss\"] = \"\"\n",
        "      analysis_df.loc[0, \"mean Valid Loss\"] = valid_loss\n",
        "      analysis_df.loc[0, \"std Valid Loss\"] = \"\"\n",
        "\n",
        "      print()\n",
        "      print(f\"Finished Training for model\")\n",
        "      print(f\"-------------------------------------------------\")\n",
        "      print(f\"-------------------------------------------------\")\n",
        "      print()\n",
        "      print()\n",
        "\n",
        "  return analysis_df"
      ],
      "metadata": {
        "id": "Q6Gw1NHH-bQO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN"
      ],
      "metadata": {
        "id": "R4SDJPLibtPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters=22\n",
        "img_folder_path=\"/content/data/VOCdevkit/VOC2012/JPEGImages\"\n",
        "annotation_folder_path=\"/content/data/VOCdevkit/VOC2012/Annotations\"\n",
        "min_cluster_size=5\n",
        "split_size=0.8\n",
        "n_classes=21\n",
        "EPOCH=5\n",
        "print_feq=100\n",
        "LR=1e-3\n",
        "BS=4\n",
        "momentum=0.9\n",
        "weight_decay=5e-4\n",
        "\n",
        "\"\"\"\n",
        "main function\n",
        "\n",
        "Arguments:\n",
        "    download - (bool, default=True) - To download the data\n",
        "    n_clusters - (int, default=22) - No. of clusters\n",
        "    n_data - (int, default=500) -  No. of data to sample from whole set\n",
        "    method - (str, default='m1') -  different methods for feature extraction\n",
        "    img_folder_path - (str) -  path to directory of images\n",
        "    annotation_folder_path - (str) - path to directory of annotations\n",
        "    cluster_visualization - (bool, default=False): to perform visualization of clusters\n",
        "    train - (bool, default=True) - to perform training\n",
        "    TrainWithClustering - (bool, default=True) - to train with partitioning the data\n",
        "    min_cluster_size - (int, default=5) - minimum cluster size for training to be performed\n",
        "    split_size - (float, default=0.8) - split % for train & val\n",
        "    n_classes - (int, default=21) - No. of classes in the data labels\n",
        "    EPOCH - (int, default=5) - no. of epochs\n",
        "    LR - (float, default=1e-3) - Learning Rate\n",
        "    BS - (float, default=4) - batch size\n",
        "    momentum - (float, default=0.9) - momentum while optimizing through Adam\n",
        "    weight_decay - (float, default=5e-4) - weight decay\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "7wNASaYQh9hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = onceInit(kCUDA=True)  # get the device and init random seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2Ytv-y4DHkM",
        "outputId": "c71b5ee8-4ad4-457b-ce02-b1f774be78be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchutils.onceInit device = cuda:0\n",
            "initSeeds(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_file_paths, label_map, class_labels, X_encoded = data_prep(download=True, img_folder_path=img_folder_path, annotation_folder_path=annotation_folder_path, method='m1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "fb6d8df7cf4e4acbab75940c2e2f307a",
            "0ee434630b8649f69238fcf7b65e3f01",
            "66963fbb43e34421845668915ddc7110",
            "440e12d774064a8da5ae62b629913fcf",
            "ec8bca41d515468ca7a6d0cb3cf26a60",
            "166be5610c89472daf4d10888e627b8d",
            "5d995954b6994ab6a8328955f67a9c11",
            "88f8c54070bd41c1898f536acbd2fad3",
            "08fda4ad79ad42fa9a7a20832fd3080c",
            "23ca5ef575f44f7e978464a93af6a587",
            "0692c03d29ed4b2c856f2a3f9fc216ed",
            "3a9ca857c72a49c9949343060ceeef5c",
            "60177a23aac54b27bcd0fb187091b4c4",
            "ce8bb90cefce4b3b9cd6984d210fc2e8",
            "9370d5350e29472182c6bc269b464898",
            "f4ffdcb28f524e2fbebe3641ca6e37f9",
            "76102057c0404b37bada42bbe5832e46",
            "43ca3c06096b4985935e70d6e7f1f18e",
            "3bd209fb99a44ea38cb44297e2b7dd56",
            "d6bb8164d68749c085ed4398d12e7131",
            "e2a328189ef6407fb256d19557ab8722",
            "798d1dd564da4fb09a9c075a7995ef75"
          ]
        },
        "id": "JsFF0nwjCzGk",
        "outputId": "b099be35-f7ab-4afa-b9ea-049947871cb2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to ./data/VOCtrainval_11-May-2012.tar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb6d8df7cf4e4acbab75940c2e2f307a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1999639040 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a9ca857c72a49c9949343060ceeef5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded base model.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_labels = clusterANDvisual(X_encoded=X_encoded, img_file_paths=img_file_paths, img_folder_path=img_folder_path, n_clusters=22, cluster_visualization=True)"
      ],
      "metadata": {
        "id": "4NteXU0ODOkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with method='m1'\n",
        "analysis_df = trainSSD(\n",
        "                       img_file_paths=img_file_paths,\n",
        "                       class_labels=class_labels, \n",
        "                       cluster_labels=cluster_labels,\n",
        "                       label_map=label_map,\n",
        "                       img_folder_path=img_folder_path,\n",
        "                       annotation_folder_path=annotation_folder_path,\n",
        "                       TrainWithClustering=False\n",
        "                       )"
      ],
      "metadata": {
        "id": "Bk-4_8fhDp60"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SSD_Clustering5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb6d8df7cf4e4acbab75940c2e2f307a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0ee434630b8649f69238fcf7b65e3f01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66963fbb43e34421845668915ddc7110",
              "IPY_MODEL_440e12d774064a8da5ae62b629913fcf",
              "IPY_MODEL_ec8bca41d515468ca7a6d0cb3cf26a60"
            ]
          }
        },
        "0ee434630b8649f69238fcf7b65e3f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66963fbb43e34421845668915ddc7110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_166be5610c89472daf4d10888e627b8d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d995954b6994ab6a8328955f67a9c11"
          }
        },
        "440e12d774064a8da5ae62b629913fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_88f8c54070bd41c1898f536acbd2fad3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1999639040,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1999639040,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08fda4ad79ad42fa9a7a20832fd3080c"
          }
        },
        "ec8bca41d515468ca7a6d0cb3cf26a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23ca5ef575f44f7e978464a93af6a587",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1999639552/? [00:57&lt;00:00, 35014820.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0692c03d29ed4b2c856f2a3f9fc216ed"
          }
        },
        "166be5610c89472daf4d10888e627b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d995954b6994ab6a8328955f67a9c11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88f8c54070bd41c1898f536acbd2fad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08fda4ad79ad42fa9a7a20832fd3080c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23ca5ef575f44f7e978464a93af6a587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0692c03d29ed4b2c856f2a3f9fc216ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a9ca857c72a49c9949343060ceeef5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60177a23aac54b27bcd0fb187091b4c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce8bb90cefce4b3b9cd6984d210fc2e8",
              "IPY_MODEL_9370d5350e29472182c6bc269b464898",
              "IPY_MODEL_f4ffdcb28f524e2fbebe3641ca6e37f9"
            ]
          }
        },
        "60177a23aac54b27bcd0fb187091b4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce8bb90cefce4b3b9cd6984d210fc2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76102057c0404b37bada42bbe5832e46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43ca3c06096b4985935e70d6e7f1f18e"
          }
        },
        "9370d5350e29472182c6bc269b464898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3bd209fb99a44ea38cb44297e2b7dd56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6bb8164d68749c085ed4398d12e7131"
          }
        },
        "f4ffdcb28f524e2fbebe3641ca6e37f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2a328189ef6407fb256d19557ab8722",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:23&lt;00:00, 128MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_798d1dd564da4fb09a9c075a7995ef75"
          }
        },
        "76102057c0404b37bada42bbe5832e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43ca3c06096b4985935e70d6e7f1f18e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bd209fb99a44ea38cb44297e2b7dd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6bb8164d68749c085ed4398d12e7131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2a328189ef6407fb256d19557ab8722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "798d1dd564da4fb09a9c075a7995ef75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}